{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``ConvNet2d`` Demo\n",
    "\n",
    "The ``torch_tools.ConvNet2d`` model is—believe it or not—a two-dimensional convolutional neural network. The model consists of three modular components:\n",
    "\n",
    "- an encoder, which can be optionally set to any of ``torchvision``'s ResNet or VGG models.\n",
    "- an adaptive pooling layer, which can be optionally set to adaptive average pooling, max pooling, or a concatenation of both.\n",
    "- a fully-connected final block, which is simply a customisable instance of ``torch_tools.DenseNetwork``.\n",
    "\n",
    "The main useful features of the model are:\n",
    "- the ability to set the number of input channels images should have at instantiation, which you cannot do with out-of-the-box ``torchvision`` models.\n",
    "    - note—this comes with the caveat that freezing the pretrained weights becomes pointless, as the first ``conv2d`` layer of the encoder is overloaded to account for the different number of channels.\n",
    "- the ability to load the model with ``torchvision``'s ImageNet-pretrained weights, and do transfer learning with/without the pretrained weights frozen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying handwritten digits — MNIST\n",
    "\n",
    "The MNIST dataset contains greyscale images of `(28,28)` pipxels containing handwritten digits between zero and nine. It is very easy to access the MNIST data through ``torchvision``—so much so that we don't even need to use the custom ``torch_tools.DataSet`` class.\n",
    "\n",
    "So, let's get some digits!\n",
    "(Note: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch import eye\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_set = MNIST(\n",
    "    \"~/mnist_data/\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=Compose([ToTensor(), lambda x: x.repeat(3, 1, 1)]),\n",
    "    target_transform=Compose([lambda x: eye(10)[x]]),\n",
    ")\n",
    "\n",
    "valid_set = MNIST(\n",
    "    \"~/mnist_data/\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=Compose([ToTensor(), lambda x: x.repeat(3, 1, 1)]),\n",
    "    target_transform=Compose([lambda x: eye(10)[x]]),\n",
    ")\n",
    "\n",
    "print(len(train_set), len(valid_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have done quite a few things here, let's break them down.\n",
    "\n",
    "- The ``transform`` argument:\n",
    "  - we supply a ``torchvision.transfroms.Compose`` object, which simply lets you chain callable objects to modify the images.\n",
    "  - the first thing in the ``Compose`` is a ``torchvision.transforms.ToTensor``, which converts PIL images (or numpy image-like arrays) to ``torch.Tensor``s.\n",
    "  - the second thing is the lambda function, which simply repeats the greyscale ``Tensor`` three times along the channel dimension. We do this because we are going to use a pretrained model which requires three input channels.\n",
    "- The ``target_transform`` argument:\n",
    "  - The target for each image is simply encoded as an integer. ``0`` means the image contains a zero, ``1`` means the image contains a one, etc. We convent these indices to one-hot encoded vectors with the lambda function supplued to ``target_transfrom``.\n",
    "\n",
    "Let's look at a single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28]) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img, target in train_set:\n",
    "    print(img.shape, target)\n",
    "\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.title(f\"target: {target}\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is clearly a five, and the target is a one-hot vector encoding the fact that the ground truth is a five.\n",
    "\n",
    "As before, we now wrap the datasets in ``torch.utils.data.DataLoader``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_set, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we need a model, optimiser and a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet2d(\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): Sequential(\n",
      "    (0): _ConcatMaxAvgPool2d(\n",
      "      (_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (_max_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (dense_layers): DenseNetwork(\n",
      "    (0): InputBlock(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): DenseBlock(\n",
      "      (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_tools import ConvNet2d\n",
    "\n",
    "model = ConvNet2d(\n",
    "    out_feats=10,\n",
    "    pretrained=True,\n",
    "    encoder_style=\"resnet18\",\n",
    "    dense_net_kwargs={\"input_dropout\": 0.1},\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have instantiated a resnet18, with ImageNet-pretrained weights and applied a dropout to the classification layer.\n",
    "\n",
    "Now, lets set up a loss function and optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "loss_func = BCELoss(reduction=\"sum\")\n",
    "optimiser = Adam(model.parameters(), lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-tools-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e74d1994c379df6aff695ace2bf1d8e3df6b224be0e21a88aabc57cf071ea71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
