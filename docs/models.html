

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DenseNetwork &mdash; TorchTools 0.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="DataSet" href="dataset.html" />
    <link rel="prev" title="Welcome to TorchTools’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> TorchTools
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">DenseNetwork</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._conv_net_2d">ConvNet2d</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._unet">UNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._encoder_2d">Encoder2d</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._decoder_2d">Decoder2d</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._encoder_decoder_2d">EncoderDecoder2d</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-torch_tools.models._simple_conv_2d">SimpleConvNet2d</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">DataSet</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TorchTools</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>DenseNetwork</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p>.._models</p>
<section id="module-torch_tools.models._dense_network">
<span id="densenetwork"></span><h1>DenseNetwork<a class="headerlink" href="#module-torch_tools.models._dense_network" title="Permalink to this heading">¶</a></h1>
<p>A fully connected neural network model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._dense_network.DenseNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._dense_network.</span></span><span class="sig-name descname"><span class="pre">DenseNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_feats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_feats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_bnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_bnorm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._dense_network.DenseNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Dense, fully connected neural network.</p>
<p>An optional input block, which applies batch normalisation and dropout
to the inputs, followed by a series of fully-connected blocks consisting
of <code class="docutils literal notranslate"><span class="pre">Linear</span></code>, <code class="docutils literal notranslate"><span class="pre">BatchNorm1d</span></code> and <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers, followed by a
final <code class="docutils literal notranslate"><span class="pre">Linear</span></code> output layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_feats</strong> (<em>int</em>) – Number of input features to the model.</p></li>
<li><p><strong>out_feats</strong> (<em>int</em>) – Number of output features (classes).</p></li>
<li><p><strong>hidden_sizes</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – The sizes of the hidden layers (or <code class="docutils literal notranslate"><span class="pre">None</span></code>).</p></li>
<li><p><strong>input_bnorm</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should we apply batch-normalisation to the input batches?</p></li>
<li><p><strong>input_dropout</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout probability to apply to the inputs (not included if zero).</p></li>
<li><p><strong>hidden_dropout</strong> (<em>float</em><em>, </em><em>optional</em>) – The Dropout probability at each hidden layer (not included if zero).</p></li>
<li><p><strong>hidden_bnorm</strong> (<em>bool</em><em>, </em><em>optional</em>) – Should we include batch norms in the hidden layers?</p></li>
<li><p><strong>negative_slope</strong> (<em>float</em><em>, </em><em>optional</em>) – The negative slope argument to use in the <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">DenseNetwork</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DenseNetwork</span><span class="p">(</span><span class="n">in_feats</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
<span class="go">                 out_feats=2,</span>
<span class="go">                 hidden_sizes=(128, 64, 32),</span>
<span class="go">                 input_bnorm=True,</span>
<span class="go">                 input_dropout=0.1,</span>
<span class="go">                 hidden_dropout=0.25,</span>
<span class="go">                 hidden_bnorm=True,</span>
<span class="go">                 negative_slope=0.2)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-torch_tools.models._conv_net_2d">
<span id="convnet2d"></span><h1>ConvNet2d<a class="headerlink" href="#module-torch_tools.models._conv_net_2d" title="Permalink to this heading">¶</a></h1>
<p>Two-dimensional CNN model which wraps Torchvision ResNet and VGG models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._conv_net_2d.ConvNet2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._conv_net_2d.</span></span><span class="sig-name descname"><span class="pre">ConvNet2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_feats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'resnet34'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'avg-max-concat'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_net_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._conv_net_2d.ConvNet2d" title="Permalink to this definition">¶</a></dt>
<dd><p>CNN model which wraps Torchvision’s ResNet and VGG models.</p>
<dl>
<dt>The model contains:</dt><dd><p>— An encoder, taken from Torchvision’s ResNet/VGG models.</p>
<p>— An adaptive pooling layer.</p>
<p>— A fully-connected classification/regression head.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_feats</strong> (<em>int</em>) – The number of output features the model should produce (for example,
the number of classes).</p></li>
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels the model should take. Warning: if you don’t
use three input channels, the first conv layer is overwritten, which
renders freezing the encoder pointless.</p></li>
<li><p><strong>encoder_option</strong> (<em>str</em><em>, </em><em>optional</em>) – The encoder option to use. The encoders are loaded from torchvision’s
models. Options include all of torchvision’s VGG and ResNET options
(i.e. <code class="docutils literal notranslate"><span class="pre">&quot;vgg11&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;vgg11_bn&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;resnet18&quot;</span></code>, etc.).</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines whether the encoder is initialised with Torchvision’s
pretrained weights. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the model will load Torchvision’s most
up-to-date image-net-trained weights.</p></li>
<li><p><strong>pool_option</strong> (<em>str</em><em>, </em><em>optional</em>) – The type of adaptive pooling layer to use. Choose from <code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;avg-max-concat&quot;</span></code> (the latter simply concatenates the
former two). See <code class="docutils literal notranslate"><span class="pre">torch_tools.models._adaptive_pools_2d</span></code> for more
info.</p></li>
<li><p><strong>dense_net_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>optional</em>) – Keyword arguments for
<code class="docutils literal notranslate"><span class="pre">torch_tools.models._dense_network.DenseNetwork</span></code> which serves as the
classification/regression part of the model.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">ConvNet2d</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet2d</span><span class="p">(</span><span class="n">out_feats</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="go">                      in_channels=3,</span>
<span class="go">                      encoder_style=&quot;vgg11_bn&quot;,</span>
<span class="go">                      pretrained=True,</span>
<span class="go">                      pool_style=&quot;avg-max-concat&quot;,</span>
<span class="go">                      dense_net_kwargs={&quot;hidden_sizes&quot;: (1024, 1024), &quot;hidden_dropout&quot;: 0.25})</span>
</pre></div>
</div>
<p>Another potentially useful feature is the ability to <em>freeze</em> the encoder,
and take advantage of the available pretrained weights by doing transfer
learning.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">rand</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">ConvNet2d</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet2d</span><span class="p">(</span><span class="n">out_feats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch of 10 fake three-channel images of 256x256 pixels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mini_batch</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With the encoder frozen</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">frozen_encoder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without the encoder frozen (default behaviour)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">frozen_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>— Even if you load pretrained weights, but <em>don’t</em> freeze the encoder, you
will likely end up finding better performance than you would by randomly
initialising the model—even if it doesn’t make sense. Welcome to deep
learning.</p>
<p>— If you change the number of input channels, don’t bother freezing the
encoder—the first convolutional layer is overloaded and randomly
initialised.</p>
<p>— See <code class="docutils literal notranslate"><span class="pre">torch_tools.models._conv_net_2d.ConvNet2d</span></code> for more info.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_tools.models._conv_net_2d.ConvNet2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frozen_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_tools.models._conv_net_2d.ConvNet2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass <cite>batch</cite> through the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Tensor</em>) – A mini-batch of inputs with shape (N, C, H, W), where N is the
batch-size, C the number of channels and (H, W) the input
size.</p></li>
<li><p><strong>frozen_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the gradients are disabled in the encoder. If
<code class="docutils literal notranslate"><span class="pre">False</span></code>, the gradients are enabled in the encoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The result of passing <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_tools.models._unet">
<span id="unet"></span><h1>UNet<a class="headerlink" href="#module-torch_tools.models._unet" title="Permalink to this heading">¶</a></h1>
<p>UNet model for semantic segmentation.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._unet.UNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._unet.</span></span><span class="sig-name descname"><span class="pre">UNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'max'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bilinear</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._unet.UNet" title="Permalink to this definition">¶</a></dt>
<dd><p>UNet model for semantic segmentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – The number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – The number of output channels.</p></li>
<li><p><strong>features_start</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of features produced by the first convolutional block.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of layers in the <code class="docutils literal notranslate"><span class="pre">UNet</span></code>.</p></li>
<li><p><strong>pool_style</strong> (<em>str</em><em>, </em><em>optional</em>) – The pool style to use in the <code class="docutils literal notranslate"><span class="pre">DownBlock</span></code> blocks. Can be <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> or
<code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code>.</p></li>
<li><p><strong>bilinear</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use use bilinear interpolation in the upsampling layers or
not. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, we use bilinear interpolation to upsample. If
<code class="docutils literal notranslate"><span class="pre">False</span></code>, we use <code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code>.</p></li>
<li><p><strong>lr_slope</strong> (<em>float</em><em>, </em><em>optional</em>) – The negative slope argument for <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">UNet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">(</span>
<span class="go">                in_chans=3,</span>
<span class="go">                out_chans=16,</span>
<span class="go">                features_start=64,</span>
<span class="go">                num_layers=3,</span>
<span class="go">                pool_style=&quot;max&quot;,</span>
<span class="go">                bilinear=False,</span>
<span class="go">                lr_slope=0.2,</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_tools.models._unet.UNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_tools.models._unet.UNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>Tensor</em>) – A mini-batch of image-like inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The result of passing <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_tools.models._encoder_2d">
<span id="encoder2d"></span><h1>Encoder2d<a class="headerlink" href="#module-torch_tools.models._encoder_2d" title="Permalink to this heading">¶</a></h1>
<p>Two-dimensional convolutional encoder moder.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._encoder_2d.Encoder2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._encoder_2d.</span></span><span class="sig-name descname"><span class="pre">Encoder2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._encoder_2d.Encoder2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder model for image-like inputs.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">DoubleConvBlock</span></code> which produces <code class="docutils literal notranslate"><span class="pre">start_features</span></code> features, followed
by <code class="docutils literal notranslate"><span class="pre">num_blocks</span> <span class="pre">-</span> <span class="pre">1</span></code> <code class="docutils literal notranslate"><span class="pre">DownBlock</span></code> blocks. The <code class="docutils literal notranslate"><span class="pre">DoubleConvBlock</span></code>
preserves the input’s height and width, while each <code class="docutils literal notranslate"><span class="pre">DownBlock</span></code> halves
the spatial dimensions and doubles the number of channels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – The number of input channels the encoder should take.</p></li>
<li><p><strong>start_features</strong> (<em>int</em>) – The number of features the first conv block should produce.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of downsampling blocks in the encoder.</p></li>
<li><p><strong>pool_style</strong> (<em>str</em>) – The type of pooling to use when downsampling (<code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).</p></li>
<li><p><strong>lr_slope</strong> (<em>float</em>) – The negative slope argument to use in the <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">Encoder2d</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Encoder2d</span><span class="p">(</span>
<span class="go">                in_chans=3,</span>
<span class="go">                start_features=64,</span>
<span class="go">                num_blocks=4,</span>
<span class="go">                pool_style=&quot;max&quot;,</span>
<span class="go">                lr_slope=0.123,</span>
<span class="go">            )</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-torch_tools.models._decoder_2d">
<span id="decoder2d"></span><h1>Decoder2d<a class="headerlink" href="#module-torch_tools.models._decoder_2d" title="Permalink to this heading">¶</a></h1>
<p>Two-dimensional decoder model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._decoder_2d.Decoder2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._decoder_2d.</span></span><span class="sig-name descname"><span class="pre">Decoder2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bilinear</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._decoder_2d.Decoder2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple decoder model for image-like inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – The number of input channels the model should take.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – The number of output channels the decoder should produce.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of blocks to include in the decoder.</p></li>
<li><p><strong>bilinear</strong> (<em>bool</em>) – Whether to use bilinear interpolation (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or a
<code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code> to do the upsampling.</p></li>
<li><p><strong>lr_slope</strong> (<em>float</em>) – The negative slope to use in the <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-torch_tools.models._encoder_decoder_2d">
<span id="encoderdecoder2d"></span><h1>EncoderDecoder2d<a class="headerlink" href="#module-torch_tools.models._encoder_decoder_2d" title="Permalink to this heading">¶</a></h1>
<p>A simple image encoder-decoder model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._encoder_decoder_2d.EncoderDecoder2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._encoder_decoder_2d.</span></span><span class="sig-name descname"><span class="pre">EncoderDecoder2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_style</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'max'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bilinear</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._encoder_decoder_2d.EncoderDecoder2d" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple encoder-decoder pair for image-like inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – The number of input channels.</p></li>
<li><p><strong>out_chans</strong> (<em>int</em>) – The number of output layers the model should produce.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of layers in the encoder/decoder.</p></li>
<li><p><strong>features_start</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of features produced by the first conv block.</p></li>
<li><p><strong>lr_slope</strong> (<em>float</em><em>, </em><em>optional</em>) – The negative slope to use in the <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
<li><p><strong>pool_style</strong> (<em>str</em><em>, </em><em>optional</em>) – The pool style to use in the downsampling blocks
( <code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> ).</p></li>
<li><p><strong>bilinear</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether or not to upsample with bilinear interpolation ( <code class="docutils literal notranslate"><span class="pre">True</span></code> ) or
<code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code> ( <code class="docutils literal notranslate"><span class="pre">False</span></code> ).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>— Depending on the application, it may be convenient to pretrain this model
and then use it for transfer learning—hence the <code class="docutils literal notranslate"><span class="pre">frozen_encoder</span></code> and
<code class="docutils literal notranslate"><span class="pre">frozen_decoder</span></code> arguments in the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method. There are no
pretrained weights available, however.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch_tools</span> <span class="kn">import</span> <span class="n">Encoder2d</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Encoder2d</span><span class="p">(</span>
<span class="go">                in_chans=3,</span>
<span class="go">                start_features=64,</span>
<span class="go">                num_blocks=4,</span>
<span class="go">                pool_style=&quot;max&quot;,</span>
<span class="go">                lr_slope=0.123,</span>
<span class="go">            )</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torch_tools.models._encoder_decoder_2d.EncoderDecoder2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frozen_encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frozen_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torch_tools.models._encoder_decoder_2d.EncoderDecoder2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Tensor</em>) – A mini-batch of inputs.</p></li>
<li><p><strong>frozen_encoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean switch controlling whether the encoder’s gradients are
enabled or disabled (useful for transfer learning).</p></li>
<li><p><strong>frozen_decoder</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean switch controlling whether the decoder’s gradients are
enabled or disabled (useful for transfer learning).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The result of passing <code class="docutils literal notranslate"><span class="pre">batch</span></code> through the model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-torch_tools.models._simple_conv_2d">
<span id="simpleconvnet2d"></span><h1>SimpleConvNet2d<a class="headerlink" href="#module-torch_tools.models._simple_conv_2d" title="Permalink to this heading">¶</a></h1>
<p>A simple two-dimensional convolutional neural network.</p>
<dl class="py class">
<dt class="sig sig-object py" id="torch_tools.models._simple_conv_2d.SimpleConvNet2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_tools.models._simple_conv_2d.</span></span><span class="sig-name descname"><span class="pre">SimpleConvNet2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chans</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_feats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample_pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'max'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptive_pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'avg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_slope</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torch_tools.models._simple_conv_2d.SimpleConvNet2d" title="Permalink to this definition">¶</a></dt>
<dd><p>A very simple 2D CNN with an encoder, pool, and fully-connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – The number of input channels.</p></li>
<li><p><strong>out_feats</strong> (<em>int</em>) – The number of output features the fully connected layer should produce.</p></li>
<li><p><strong>features_start</strong> (<em>int</em>) – The number of features the input convolutional block should produce.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of encoding blocks to use.</p></li>
<li><p><strong>downsample_pool</strong> (<em>str</em>) – The style of downsampling pool to use in the encoder (<code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code> or
<code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).</p></li>
<li><p><strong>adaptive_pool</strong> (<em>str</em>) – The style of adaptive pool to use on the encoder’s output (<code class="docutils literal notranslate"><span class="pre">&quot;avg&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;avg-max-concat&quot;</span></code>.)</p></li>
<li><p><strong>lr_slope</strong> (<em>float</em>) – The negative slope to use in the <code class="docutils literal notranslate"><span class="pre">LeakyReLU</span></code> layers.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dataset.html" class="btn btn-neutral float-right" title="DataSet" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to TorchTools’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, J. Denholm

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>